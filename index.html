<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Whisperæ–‡å­—èµ·ã“ã— (éŸ³å£°å°‚ç”¨ç‰ˆ)</title>
  <style>
    body { font-family: sans-serif; margin: 20px; }
    input, button, textarea { display: block; margin: 10px 0; width: 100%; }
    #result { white-space: pre-wrap; background: #f4f4f4; padding: 10px; border-radius: 5px; }
  </style>
</head>
<body>
  <h1>ğŸµ Whisperæ–‡å­—èµ·ã“ã— (éŸ³å£°å°‚ç”¨)</h1>
  <p>éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚</p>

  <label for="audioFile">éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ« (mp3, wav, m4a):</label>
  <input type="file" id="audioFile" accept="audio/*">

  <button id="transcribeBtn">æ–‡å­—èµ·ã“ã—é–‹å§‹</button>

  <h2>æ–‡å­—èµ·ã“ã—çµæœ</h2>
  <div id="result">ã“ã“ã«æ–‡å­—èµ·ã“ã—çµæœãŒè¡¨ç¤ºã•ã‚Œã¾ã™</div>

  <script>
    const apiKey = prompt("OpenAI APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆsk-...ï¼‰:").trim();

    function shiftSRTTimes(srtText, shiftSeconds) {
      return srtText.replace(/(\d{2}):(\d{2}):(\d{2}),(\d{3})/g, (_, hh, mm, ss, ms) => {
        const totalSeconds = parseInt(hh) * 3600 + parseInt(mm) * 60 + parseInt(ss) + shiftSeconds;
        const newDate = new Date(totalSeconds * 1000);
        const newHH = String(newDate.getUTCHours()).padStart(2, '0');
        const newMM = String(newDate.getUTCMinutes()).padStart(2, '0');
        const newSS = String(newDate.getUTCSeconds()).padStart(2, '0');
        return `${newHH}:${newMM}:${newSS},${ms}`;
      });
    }

    async function transcribeAudio(file) {
      const resultDiv = document.getElementById('result');
      resultDiv.textContent = 'Whisper APIã§æ–‡å­—èµ·ã“ã—ä¸­...';

      const formData = new FormData();
      formData.append('file', file);
      formData.append('language', 'ja');
      formData.append('response_format', 'srt');
      formData.append('model', 'whisper-1');

      try {
        const response = await fetch('https://api.openai.com/v1/audio/transcriptions', {
          method: 'POST',
          headers: { 'Authorization': `Bearer ${apiKey}` },
          body: formData
        });

        if (!response.ok) {
          throw new Error('Whisper API ã‚¨ãƒ©ãƒ¼: ' + response.statusText);
        }

        const srtText = await response.text();

        // ğŸ”¥ ãƒ•ã‚¡ã‚¤ãƒ«åæœ«å°¾ã®æ•°å­—æ¤œå‡ºã¨10åˆ†ã‚·ãƒ•ãƒˆ
        const fileName = file.name;
        const match = fileName.match(/(\d+)(?=\.\w+$)/); // æ‹¡å¼µå­ã®å‰ã®æ•°å­—
        let adjustedSrtText = srtText;
        if (match) {
          console.log(`ãƒ•ã‚¡ã‚¤ãƒ«åæœ«å°¾ã®æ•°å­— ${match[1]} ã‚’æ¤œå‡ºã€‚10åˆ†ã‚·ãƒ•ãƒˆé©ç”¨`);
          adjustedSrtText = shiftSRTTimes(srtText, parseInt(match[1]) * 600); // 600ç§’ = 10åˆ†
        }

        resultDiv.textContent = 'âœ… æ–‡å­—èµ·ã“ã—å®Œäº† (SRTå½¢å¼):\n\n' + adjustedSrtText;
      } catch (err) {
        resultDiv.textContent = 'âŒ ã‚¨ãƒ©ãƒ¼: ' + err.message;
      }
    }

    document.getElementById('transcribeBtn').addEventListener('click', async () => {
      const fileInput = document.getElementById('audioFile');
      const file = fileInput.files[0];

      if (!file) {
        alert('éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„');
        return;
      }

      await transcribeAudio(file);
    });
  </script>
</body>
</html>
